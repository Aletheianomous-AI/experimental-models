{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8116a446-0e60-4c8b-a5ff-db4385dceb56",
   "metadata": {},
   "source": [
    "# Train Queryable Input Classifier\n",
    "This notebook trains an LSTM model that classifies whether the user's input can be queryable, in that the model should extract keywords to look online via the citation fetcher class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67203225-dff7-4daa-ba87-7adbd83d690c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext==0.5\n",
      "  Downloading torchtext-0.5.0-py3-none-any.whl (73 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 KB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six in /home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages (from torchtext==0.5) (1.16.0)\n",
      "Requirement already satisfied: numpy in /home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages (from torchtext==0.5) (1.26.4)\n",
      "Requirement already satisfied: torch in /home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages (from torchtext==0.5) (2.2.2)\n",
      "Requirement already satisfied: tqdm in /home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages (from torchtext==0.5) (4.66.2)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages (from torchtext==0.5) (2.31.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages (from requests->torchtext==0.5) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages (from requests->torchtext==0.5) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages (from requests->torchtext==0.5) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages (from requests->torchtext==0.5) (2024.2.2)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages (from torch->torchtext==0.5) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages (from torch->torchtext==0.5) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages (from torch->torchtext==0.5) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages (from torch->torchtext==0.5) (2.19.3)\n",
      "Requirement already satisfied: jinja2 in /home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages (from torch->torchtext==0.5) (3.1.3)\n",
      "Requirement already satisfied: sympy in /home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages (from torch->torchtext==0.5) (1.12)\n",
      "Requirement already satisfied: filelock in /home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages (from torch->torchtext==0.5) (3.13.3)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages (from torch->torchtext==0.5) (11.4.5.107)\n",
      "Requirement already satisfied: networkx in /home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages (from torch->torchtext==0.5) (3.3)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages (from torch->torchtext==0.5) (12.1.105)\n",
      "Requirement already satisfied: fsspec in /home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages (from torch->torchtext==0.5) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages (from torch->torchtext==0.5) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages (from torch->torchtext==0.5) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages (from torch->torchtext==0.5) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages (from torch->torchtext==0.5) (12.1.3.1)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages (from torch->torchtext==0.5) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages (from torch->torchtext==0.5) (12.1.105)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages (from torch->torchtext==0.5) (4.11.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->torchtext==0.5) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages (from jinja2->torch->torchtext==0.5) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages (from sympy->torch->torchtext==0.5) (1.3.0)\n",
      "Installing collected packages: sentencepiece, torchtext\n",
      "  Attempting uninstall: torchtext\n",
      "    Found existing installation: torchtext 0.17.2\n",
      "    Uninstalling torchtext-0.17.2:\n",
      "      Successfully uninstalled torchtext-0.17.2\n",
      "Successfully installed sentencepiece-0.2.0 torchtext-0.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext==0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfda3faf-9cd4-4bc7-82af-c7f2a5d02239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from torchtext import data, datasets\n",
    "\n",
    "import const\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import torchtext\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import spacy\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04117aea-a4cb-43a3-a36e-26416fdc52de",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(tokenize=\"spacy\", tokenizer_language=\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a782d70e-d84a-4320-9d01-ed601dc761a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = data.LabelField(dtype= torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96acec81-6afe-4ae8-8eea-bd9041642904",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DS_PATH = const.DATASETS_FOLDER + \"QI_training.csv\"\n",
    "TESTING_DS_PATH = const.DATASETS_FOLDER + \"QI_testing.csv\"\n",
    "\n",
    "FEATURE_COL = \"question\"\n",
    "LABEL_COL = \"is_searchable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "077b9106-2375-4529-be2b-01473526d003",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS_SIZE = 25000\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 5\n",
    "\n",
    "EMBEDDING_DIM = 256\n",
    "HIDDEN_DIM = 512\n",
    "OUTPUT_DIM = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd6e77ef-7a71-40ee-8a3b-1b1e83acce19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_396305/3303508223.py:1: DtypeWarning: Columns (2,3,4,6,7,8,9,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  training_df = pd.read_csv(TRAINING_DS_PATH)\n"
     ]
    }
   ],
   "source": [
    "training_df = pd.read_csv(TRAINING_DS_PATH)\n",
    "testing_df = pd.read_csv(TESTING_DS_PATH)\n",
    "\n",
    "training_df = training_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1ce62d7-d26e-4725-908d-eb285e52c552",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds = Dataset.from_pandas(training_df)\n",
    "validation_ds = Dataset.from_pandas(testing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "818fd65e-1ec3-4e2f-9b3f-b3849b2a5f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25b56cd2-eb86-459b-986a-fade037fa956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bddaec8506c946c38a458d427793a233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/204726 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer_funct = lambda input_sample, tokenizer: {'tokens': tokenizer(input_sample[FEATURE_COL] + \"<eos>\")}\n",
    "#label_tokenizer_funct = lambda input_sample, tokenizer: {'label_tokens': tokenizer(input_sample[LABEL_COL] + \"<eos>\")}\n",
    "training_ds = training_ds.map(tokenizer_funct, fn_kwargs={'tokenizer': tokenizer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c40f8e3-6cce-46c8-8619-7df24a5876b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'know',\n",
       " ',',\n",
       " 'but',\n",
       " 'I',\n",
       " 'always',\n",
       " 'get',\n",
       " 'my',\n",
       " 'hopes',\n",
       " 'up',\n",
       " 'for',\n",
       " 'no',\n",
       " 'reason',\n",
       " '.',\n",
       " '<',\n",
       " 'eos',\n",
       " '>']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_ds[204000]['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "148d9983-9f84-43ef-b8dc-6b30f9437c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_cl_count = len(training_df[training_df['is_searchable'] == True])\n",
    "negative_cl_count = len(training_df[training_df['is_searchable'] == False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01b87916-6d57-42bc-97d2-ec346a639118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165319\n",
      "39407\n"
     ]
    }
   ],
   "source": [
    "print(positive_cl_count)\n",
    "print(negative_cl_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2cb504e-e75e-4212-944d-67072825056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_len = len(training_df)\n",
    "positive_weight = positive_cl_count / training_len\n",
    "negative_weight = negative_cl_count / training_len\n",
    "weights = [positive_weight, negative_weight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "072c0e13-9a61-479b-9bf3-14ff11f38cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.807513457010834, 0.192486542989166]\n"
     ]
    }
   ],
   "source": [
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ed9d6fc-b199-4e74-927c-1a01666e9bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<eos>', '>', 'the', 'What', 'of', 'in', 'to', 'and', 'is']\n"
     ]
    }
   ],
   "source": [
    "vocab = torchtext.vocab.build_vocab_from_iterator(training_ds['tokens'], min_freq=3)\n",
    "vocab.insert_token('<unk>', 0)\n",
    "vocab.insert_token('<eos>', 1)\n",
    "vocab.set_default_index(vocab['<unk>'])\n",
    "print(vocab.get_itos()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a54a6ca-1f51-4da9-a167-ca44330e6076",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QIClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=2,\n",
    "              batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid(dim=1)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded_text = self.embedding(text)\n",
    "        output, hidden = self.rnn(embedded_text)\n",
    "        logits = self.fc(output[:, -1, :])\n",
    "        output = self.sigmoid(logits)\n",
    "        return logits, output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f51a04ba-2772-49fa-9d8b-02116fedfff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(ds, vocab, batch_size):\n",
    "    data = []\n",
    "    for example in ds:\n",
    "        tokens = [vocab[token] for token in example]\n",
    "        data.extend(tokens)\n",
    "    data = torch.LongTensor(data)\n",
    "    num_batches = data.shape[0]\n",
    "    data = data[:num_batches * batch_size]\n",
    "    data = data.view(batch_size, num_batches)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c668e76-8d50-4409-b5c3-df800d97d568",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[8, 2529594]' is invalid for input of size 2529594",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m out_data \u001b[38;5;241m=\u001b[39m \u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_ds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtokens\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[42], line 9\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(ds, vocab, batch_size)\u001b[0m\n\u001b[1;32m      7\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      8\u001b[0m data \u001b[38;5;241m=\u001b[39m data[:num_batches \u001b[38;5;241m*\u001b[39m batch_size]\n\u001b[0;32m----> 9\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[8, 2529594]' is invalid for input of size 2529594"
     ]
    }
   ],
   "source": [
    "out_data = get_data(training_ds['tokens'], vocab, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c6a5d183-3363-41c2-a9b2-1c9584ff0d98",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtraining_data\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_data' is not defined"
     ]
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bd0529-6901-4afc-ba14-8e972f8d7a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(feat_data, seq_len, batch_size, batch_id):\n",
    "    feature = feat_data[:, idx:idx+seq_len]\n",
    "    label = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb0e2c6-47fb-4f3a-a1be-11c4f2ed5bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, training_ds, epochs=10, device=\"cpu\", epoch_timestamp=1, lr=0.001):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    epoch_modulus: int\n",
    "    for i in range(epochs):\n",
    "        epoch_modulus = i % epoch_timestamp\n",
    "        for X_batch, y_batch in enumerate(ds):\n",
    "            X_tensor = torch.tensor(X_batch, dtype=torch.float64, device=device)\n",
    "            Y_tensor = torch.tensor(y_batch, dtype=torch.float64, device=device)\n",
    "            logits, out = model(X_tensor)\n",
    "            optimizer.zero_grad()\n",
    "            cost = loss(logits, Y_tensor.to(torch.long))\n",
    "            cost.backward()\n",
    "            optimizer.step()\n",
    "            if epoch_timestamp == 1:\n",
    "                print(\"Epoch \" + str(i + 1) + \"/\" + str(epochs) + \" loss: \" + str(cost))\n",
    "            elif epoch_timestamp > 1:\n",
    "                if epoch_modulus == epoch_timestamp - 1:\n",
    "                    end_line = \"\\n\"\n",
    "                else:\n",
    "                    end_line = \"                        \\r\"\n",
    "                print(\"Epoch \" + str(i + 1) + \"/\" + str(epochs) + \" loss: \" + str(cost), end=end_line)\n",
    "            else:\n",
    "                raise ValueError(\"Expected epoch_timestamp parameter to be a non-negative number but got \" + str(epoch_timestamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1159b055-ee06-441c-bb2c-1f7e7ed2205e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, const.MODELS_FOLDER + \"Aletheianomous-AI_QI_classifier.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
