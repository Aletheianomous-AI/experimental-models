{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Keywords Ground Truth\n",
    "This notebook generates the ground truth dataset for search keywords, given user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import *\n",
    "from transformers import pipeline\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import const\n",
    "import ctypes\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import torch\n",
    "import traceback\n",
    "import yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYWORD_GEN_MODEL = \"yake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ds = pd.read_csv(const.DATASETS_FOLDER + \"squad-test-v2.0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = Value(ctypes.py_object)\n",
    "k.value = temp_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(k.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_keywords(ds_ns, start_row, end_row, batch_size = 64):\n",
    "    #print(\"start: \" + str(start_row) + \", end: \" + str(end_row))\n",
    "    temp_ds = ds_ns.df\n",
    "    row_len = end_row - start_row\n",
    "    if row_len <= batch_size:\n",
    "        kw_extr = yake.KeywordExtractor(n=16)\n",
    "        for row in range(start_row, end_row):\n",
    "            keywords = kw_extr.extract_keywords(temp_ds.loc[row, \"question\"])\n",
    "            if keywords == []:\n",
    "                    print(\"No keywords extracted at row \" + str(row) + \" (question: \" + temp_ds.loc[row, \"question\"] + \")\")\n",
    "            else:\n",
    "                temp_ds.loc[row, \"keyword\"] = keywords[0][0]\n",
    "            alt_keywords = []\n",
    "            for item in keywords:\n",
    "                alt_keywords.append(item[0])\n",
    "            temp_ds.loc[row, \"possible_keywords\"] = str(alt_keywords)\n",
    "        ds_ns.df = temp_ds\n",
    "    else:\n",
    "        row_range = end_row - start_row\n",
    "        left_start = start_row\n",
    "        left_end = int((row_range)/2) + left_start\n",
    "        right_start = start_row + int((row_range)/2)\n",
    "        right_end = end_row\n",
    "\n",
    "        left_mgr = Manager()\n",
    "        right_mgr = Manager()\n",
    "        left_ns = left_mgr.Namespace()\n",
    "        right_ns = right_mgr.Namespace()\n",
    "\n",
    "        left_ns.df = ds_ns.df[0:int(row_range/2)].copy()\n",
    "        right_ns.df = ds_ns.df[int(row_range/2):row_range].copy()\n",
    "        p_left = Process(target=generate_keywords, args=(left_ns, left_start, left_end, batch_size))\n",
    "        p_right = Process(target=generate_keywords, args=(right_ns, right_start, right_end, batch_size))\n",
    "        p_left.start()\n",
    "        p_right.start()\n",
    "        p_left.join()\n",
    "        p_right.join()\n",
    "        ds_ns.df = pd.concat([left_ns.df, right_ns.df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_keywords_by_zephyr(model, ds):\n",
    "    questions_processed = 0\n",
    "    samples_len = len(ds)\n",
    "    start_dt = dt.now()\n",
    "    end_dt = None\n",
    "    for row in range(len(ds)):\n",
    "        content_msg = (\"Hello Zephyr. I am creating a dataset that contains questions about topics. \" + \n",
    "       \"The questions may be asked by the user, thus it is a feature in the dataset I am creating. \" +\n",
    "       \"Keywords are the dataset's label, which are keywords that can \" +\n",
    "       \"be searched online to answer the user's questions. Please generate a kewyord that answers the following question in \" +\n",
    "       \"quotation marks: \\\"\")\n",
    "        progress = int(questions_processed / samples_len) * 100\n",
    "        progr_msg = (\"Generating keywords... \" + str(progress) + \"% (\"\n",
    "            + \"samples: \" + str(questions_processed + 1) + \"/\" + str(samples_len))\n",
    "        if end_dt is None:\n",
    "            progr_msg += \", Elapsed time: 00:00.00)\"\n",
    "        else:\n",
    "            elapsed_time = end_dt - start_dt\n",
    "            avg_time = elapsed_time / questions_processed\n",
    "            samples_remaining = samples_len - questions_processed\n",
    "            time_remaining = avg_time * (samples_remaining)\n",
    "            progr_msg += \", Elapsed time: \" + str(elapsed_time) + \", \"\n",
    "            progr_msg += \"Time remaining: \" + str(time_remaining) + \")\"\n",
    "        print(progr_msg, end=\"                                                           \\r\")        \n",
    "        question = ds.loc[row, \"question\"]\n",
    "        content_msg += question + \"\\\"\"\n",
    "        msg = [{\"role\": \"user\", \"content\": content_msg}]\n",
    "        prompt = zephyr.tokenizer.apply_chat_template(msg, tokenize=False, add_generation_prompt=True)\n",
    "        model_output = zephyr(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n",
    "        model_output = model_output[0]\n",
    "        model_output = model_output['generated_text']\n",
    "        model_output = model_output.split(\"<|assistant|>\\n\")\n",
    "        keyword = model_output[1]\n",
    "        if keyword == None:\n",
    "                print(\"No keywords extracted at row \" + str(row) + \" (question: \" + ds.loc[row, \"question\"] + \")\")\n",
    "        else:\n",
    "            ds.loc[row, \"keyword\"] = keyword\n",
    "        end_dt = dt.now()\n",
    "        questions_processed += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if KEYWORD_GEN_MODEL == \"yake\":\n",
    "\n",
    "elif KEYWORD_GEN_MODEL == \"zephyr\":\n",
    "    zephyr = pipeline(\"text-generation\", model=\"HuggingFaceH4/zephyr-7b-alpha\",\n",
    "                 torch_dtype = torch.bfloat16, device_map=\"auto\")\n",
    "    generate_keywords_by_zephyr(zephyr, temp_ds)\n",
    "else:\n",
    "    raise ValueError(KEYWORD_GEN_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zephyr = pipeline(\"text-generation\", model=\"HuggingFaceH4/zephyr-7b-alpha\",\n",
    "#                 torch_dtype = torch.bfloat16, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_keywords_by_zephyr(zephyr, temp_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_ds.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_ds['keyword']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_ds['is_searchable'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_ds.to_csv(const.DATASETS_FOLDER + \"squad_ds_keyword_ground_truth.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
