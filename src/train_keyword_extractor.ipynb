{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a54244da-2662-4964-beb9-df14f37fc860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import const\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from datasets import Dataset\n",
    "from trl import SFTTrainer\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, pipeline, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80821fbf-7d35-47ca-a4e8-881e60511d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OUTPUT_NAME = const.MODELS_FOLDER + \"aletheianomous_ai-keyword_extractor-v0.3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72846b5a-82a7-4978-89c1-0cbee68b46c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edd452b2-793d-4e62-9224-593ae6076d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a44038e861428eb3eb5cb6168ac3ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_df = pd.read_csv(const.DATASETS_FOLDER + \"squad_ds_keyword_train.csv\")\n",
    "training_df = training_df[0:1000]\n",
    "training_df = training_df.sample(frac=1)\n",
    "zephyr = AutoModelForCausalLM.from_pretrained(\"HuggingFaceH4/zephyr-7b-alpha\", quantization_config=bnb_config, device_map=\"auto\", torch_dtype=torch.bfloat16, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceH4/zephyr-7b-alpha\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2696640b-7268-484b-b6f5-bad48b51d021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source</th>\n",
       "      <th>topic</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>question</th>\n",
       "      <th>question_id</th>\n",
       "      <th>is_impossible</th>\n",
       "      <th>answers</th>\n",
       "      <th>expanded_answers</th>\n",
       "      <th>keyword</th>\n",
       "      <th>possible_keywords</th>\n",
       "      <th>is_searchable</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>396</td>\n",
       "      <td>396</td>\n",
       "      <td>Squad 2.0</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Forbes magazine began reporting on Beyoncé's e...</td>\n",
       "      <td>Beyonce beat out which musical artists for mos...</td>\n",
       "      <td>56beb4023aeaaa14008c9252</td>\n",
       "      <td>False</td>\n",
       "      <td>Madonna and Celine Dion</td>\n",
       "      <td>on. They placed her fourth on the Celebrity 10...</td>\n",
       "      <td>musical artists Beyonce beat for most paid bet...</td>\n",
       "      <td>['Beyonce beat out which musical artists for m...</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;|system|&gt;\\nYou are a chatbot that assists in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>Squad 2.0</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>On April 4, 2008, Beyoncé married Jay Z. She p...</td>\n",
       "      <td>When did Beyonce begin her second world tour?</td>\n",
       "      <td>56bf97aba10cfb140055119f</td>\n",
       "      <td>False</td>\n",
       "      <td>March 2009</td>\n",
       "      <td>8 in the United States. The album formally int...</td>\n",
       "      <td>Year Beyonce began her second world tour</td>\n",
       "      <td>['Beyonce begin her second world tour', 'Beyon...</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;|system|&gt;\\nYou are a chatbot that assists in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>594</td>\n",
       "      <td>594</td>\n",
       "      <td>Squad 2.0</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé's work has influenced numerous artists...</td>\n",
       "      <td>Which Indie band said Beyoncé was an inspirati...</td>\n",
       "      <td>56d4e9d12ccc5a1400d8333a</td>\n",
       "      <td>False</td>\n",
       "      <td>White Rabbits</td>\n",
       "      <td>erican indie rock band White Rabbits also cite...</td>\n",
       "      <td>Indie band said Beyoncé was an inspiration for...</td>\n",
       "      <td>['Indie band said Beyoncé was an inspiration f...</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;|system|&gt;\\nYou are a chatbot that assists in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>Squad 2.0</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé has received numerous awards. As a sol...</td>\n",
       "      <td>Totaling worldwide, how many records as Beyonc...</td>\n",
       "      <td>56becb8d3aeaaa14008c9496</td>\n",
       "      <td>False</td>\n",
       "      <td>118 million</td>\n",
       "      <td>rding Industry Association of America (RIAA) l...</td>\n",
       "      <td>records as Beyonce sold</td>\n",
       "      <td>['records as Beyonce sold', 'Beyonce sold', 'T...</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;|system|&gt;\\nYou are a chatbot that assists in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>987</td>\n",
       "      <td>987</td>\n",
       "      <td>Squad 2.0</td>\n",
       "      <td>Frédéric_Chopin</td>\n",
       "      <td>Chopin arrived in Paris in late September 1831...</td>\n",
       "      <td>What language was Chopin never completely at e...</td>\n",
       "      <td>56d318f359d6e41400146238</td>\n",
       "      <td>False</td>\n",
       "      <td>French</td>\n",
       "      <td>on a French passport. However, Chopin remaine...</td>\n",
       "      <td>language was Chopin never completely at ease s...</td>\n",
       "      <td>['language was Chopin never completely at ease...</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;|system|&gt;\\nYou are a chatbot that assists in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0.1  Unnamed: 0     source            topic  \\\n",
       "384           396         396  Squad 2.0          Beyoncé   \n",
       "181           181         181  Squad 2.0          Beyoncé   \n",
       "582           594         594  Squad 2.0          Beyoncé   \n",
       "600           612         612  Squad 2.0          Beyoncé   \n",
       "975           987         987  Squad 2.0  Frédéric_Chopin   \n",
       "\n",
       "                                             paragraph  \\\n",
       "384  Forbes magazine began reporting on Beyoncé's e...   \n",
       "181  On April 4, 2008, Beyoncé married Jay Z. She p...   \n",
       "582  Beyoncé's work has influenced numerous artists...   \n",
       "600  Beyoncé has received numerous awards. As a sol...   \n",
       "975  Chopin arrived in Paris in late September 1831...   \n",
       "\n",
       "                                              question  \\\n",
       "384  Beyonce beat out which musical artists for mos...   \n",
       "181      When did Beyonce begin her second world tour?   \n",
       "582  Which Indie band said Beyoncé was an inspirati...   \n",
       "600  Totaling worldwide, how many records as Beyonc...   \n",
       "975  What language was Chopin never completely at e...   \n",
       "\n",
       "                  question_id is_impossible                  answers  \\\n",
       "384  56beb4023aeaaa14008c9252         False  Madonna and Celine Dion   \n",
       "181  56bf97aba10cfb140055119f         False               March 2009   \n",
       "582  56d4e9d12ccc5a1400d8333a         False            White Rabbits   \n",
       "600  56becb8d3aeaaa14008c9496         False              118 million   \n",
       "975  56d318f359d6e41400146238         False                   French   \n",
       "\n",
       "                                      expanded_answers  \\\n",
       "384  on. They placed her fourth on the Celebrity 10...   \n",
       "181  8 in the United States. The album formally int...   \n",
       "582  erican indie rock band White Rabbits also cite...   \n",
       "600  rding Industry Association of America (RIAA) l...   \n",
       "975   on a French passport. However, Chopin remaine...   \n",
       "\n",
       "                                               keyword  \\\n",
       "384  musical artists Beyonce beat for most paid bet...   \n",
       "181           Year Beyonce began her second world tour   \n",
       "582  Indie band said Beyoncé was an inspiration for...   \n",
       "600                            records as Beyonce sold   \n",
       "975  language was Chopin never completely at ease s...   \n",
       "\n",
       "                                     possible_keywords is_searchable  \\\n",
       "384  ['Beyonce beat out which musical artists for m...          True   \n",
       "181  ['Beyonce begin her second world tour', 'Beyon...          True   \n",
       "582  ['Indie band said Beyoncé was an inspiration f...          True   \n",
       "600  ['records as Beyonce sold', 'Beyonce sold', 'T...          True   \n",
       "975  ['language was Chopin never completely at ease...          True   \n",
       "\n",
       "                                                  text  \n",
       "384  <|system|>\\nYou are a chatbot that assists in ...  \n",
       "181  <|system|>\\nYou are a chatbot that assists in ...  \n",
       "582  <|system|>\\nYou are a chatbot that assists in ...  \n",
       "600  <|system|>\\nYou are a chatbot that assists in ...  \n",
       "975  <|system|>\\nYou are a chatbot that assists in ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f93d353-fc1f-4d40-940e-f176f073c017",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds = Dataset.from_pandas(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed05c693-329e-4ecd-82b3-7ec0e6d82318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1756321b-5f3d-4612-b19c-5ed385b6b89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eef4f04a-4c03-4ebb-bdc7-4c6818d55319",
   "metadata": {},
   "outputs": [],
   "source": [
    "zephyr.config.use_cache = False\n",
    "zephyr.config.pretraining_tp = 1\n",
    "zephyr.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c4ddef1-149b-40a4-8417-cafbe64e6801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096, padding_idx=2)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralSdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zephyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e4a9531-3426-493a-acac-c0e9174a4cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.padding_side = 'right'\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "tokenizer.add_eos_token = True\n",
    "zephyr = prepare_model_for_kbit_training(zephyr)\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "996b25c3-00d6-4c5b-b415-04a0db340258",
   "metadata": {},
   "outputs": [],
   "source": [
    "zephyr = get_peft_model(zephyr, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "baa8a927-68c7-47de-99b2-11086f4da0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dced07ea1cf346158bbd81dab65677df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = const.MODELS_FOLDER + \"/keyword-extractor\",\n",
    "    per_device_train_batch_size = 4,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=25,\n",
    "    logging_steps=25,\n",
    "    learning_rate=1e-4,\n",
    "    warmup_ratio=0.03,\n",
    "    weight_decay=0.001,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm = 0.3,\n",
    "    max_steps=-1,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    num_train_epochs=3,\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=zephyr,\n",
    "    train_dataset=training_ds, \n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=2048,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    packing=False\n",
    ")\n",
    "\n",
    "#trainer = Trainer(\n",
    "#    model=zephyr, \n",
    "#    train_dataset=training_ds['text'],\n",
    "#    tokenizer=tokenizer,\n",
    "#    args=training_args\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5708682-41ef-4672-b30c-6602b52d8cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='84' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 84/750 02:51 < 23:11, 0.48 it/s, Epoch 0.33/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.911400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.421700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.565900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/sp15-chatbot/Documents/experimental-models/.env/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/experimental-models/.env/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:361\u001b[0m, in \u001b[0;36mSFTTrainer.train\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trl_activate_neftune(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m--> 361\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# After training we make sure to retrieve back the original forward pass method\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;66;03m# for the embedding layer by removing the forward post hook.\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n",
      "File \u001b[0;32m~/Documents/experimental-models/.env/lib/python3.10/site-packages/transformers/trainer.py:1780\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1778\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1780\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1782\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1783\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/experimental-models/.env/lib/python3.10/site-packages/transformers/trainer.py:2118\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2117\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2118\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2121\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2122\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2123\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2124\u001b[0m ):\n\u001b[1;32m   2125\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2126\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/Documents/experimental-models/.env/lib/python3.10/site-packages/transformers/trainer.py:3045\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3043\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   3044\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3045\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3047\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m~/Documents/experimental-models/.env/lib/python3.10/site-packages/accelerate/accelerator.py:2013\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2011\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2012\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2013\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/experimental-models/.env/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/experimental-models/.env/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce27b13-15fe-4c17-b8f2-a92217ad1b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(MODEL_OUTPUT_NAME)\n",
    "tokenizer.save_pretrained(MODEL_OUTPUT_NAME + \"/tokenizer\")\n",
    "zephyr.config.use_cache = True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "experimental-env",
   "language": "python",
   "name": "experimental-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
