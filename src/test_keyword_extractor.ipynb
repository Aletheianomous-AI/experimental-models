{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "061b375d-69bd-485b-9297-9762dcc223af",
   "metadata": {},
   "source": [
    "# Test Keyword Extractor\n",
    "This function tests the keyword extractor model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c3445dc-4654-4f8c-9660-3422f56a01bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from datetime import datetime as dt\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, pipeline\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "\n",
    "import const\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c56ea4ef-9d67-475a-b6f2-920a7786e7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "KW_MODEL_PATH = const.MODELS_FOLDER + \"aletheianomous_ai-keyword_extractor-v0.3.1/\"\n",
    "TESTING_DS = const.DATASETS_FOLDER + \"squad_ds_keyword_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da7faa5a-597b-4210-932b-bd007cd68e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dff58d7-0848-44f4-8883-1613763caed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d80c317e005348078855ab7fb75a7d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kw_model = AutoModelForCausalLM.from_pretrained(KW_MODEL_PATH, quantization_config=bnb_config,\n",
    "    device_map=\"auto\", torch_dtype=torch.bfloat16, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(KW_MODEL_PATH + \"tokenizer\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ad16889-143a-4a79-b5e8-ccb07d2cdb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.padding_side = 'right'\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "tokenizer.add_eos_token = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "210ac576-6f15-4902-9a0c-f616e8177aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0231ec37-3df7-4437-a7a7-fa885de43032",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_ds = pd.read_csv(TESTING_DS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e91a7371-ec18-468b-8faf-357d595031b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|system|>\\nYou are a chatbot that assists in providing information to the user. Please generate a keyword from the user's question.</s>\\n<|user|>\\nIn what country is Normandy located?</s>\\n<|assistant|>\\ncountry is Normandy located\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_ds.loc[0, \"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57ac0566-3c14-4333-9fb9-3947c0941b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_chat_template(user_prompt):\n",
    "    prompt = (\"<|system|>\\nYou are a chatbot \" +\n",
    "              \"that assists in providing \" + \n",
    "              \"information to the user. \" + \n",
    "              \"Please generate a keyword \" + \n",
    "              \"from the user's question.</s>\\n<|user|>\\n\")\n",
    "    prompt += user_prompt\n",
    "    prompt += \"</s>\\n<|assistant|>\\n\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79d99754-95d0-4105-943e-ba01293da950",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"Who is Da Regular Sauce?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d63f6108-727e-40fa-810e-8cf18b2a96d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = apply_chat_template(user_prompt)\n",
    "kw_pipe = pipeline(\"text-generation\", model=kw_model, tokenizer = tokenizer, torch_dtype=torch.bfloat16,\n",
    "      device_map=\"auto\", batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdc5446e-ca78-4d82-a52a-5c7c57150732",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_out = kw_pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a170013-5387-45dc-9b4a-42c96abed08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"<|system|>\\nYou are a chatbot that assists in providing information to the user. Please generate a keyword from the user's question.</s>\\n<|user|>\\nWho is Da Regular Sauce?</s>\\n<|assistant|>\\nDa Regular Sauce\"}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "823d8741-f43d-4e2e-9d51-af14d8ab4587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_prompt(prompt):\n",
    "    for sample in prompt:\n",
    "        #print(sample)\n",
    "        yield sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7735eaca-5c2e-4251-96c2-a8273dfaf332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_prompts_for_val(val_feats):\n",
    "    prompt_ls = []\n",
    "    i = 1\n",
    "    val_feats_len = len(val_feats)\n",
    "    percentage = 0\n",
    "    for prompt in val_feats:\n",
    "        (print(\"Tokenizing prompts...\", percentage, \"% (\", i, \"/\", val_feats_len, \")\", \n",
    "              end=\"                                                           \\r\"))\n",
    "        prompt_ls.append(apply_chat_template(prompt))\n",
    "        i+=1\n",
    "        percentage = (i/val_feats_len) * 100\n",
    "    #prompts_df = pd.DataFrame(data={\"prompt\": prompt_ls})\n",
    "    #prompt_ls = Dataset.from_pandas(prompts_df)\n",
    "    return prompt_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed67a802-54aa-4a6a-9741-44ce7a449754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_to_np(predictions):\n",
    "    pred_ls = []\n",
    "    percent = 0\n",
    "    item_num = 1\n",
    "    pred_len = len(predictions)\n",
    "    for item in predictions:\n",
    "        #print(item)\n",
    "        print(\"Converting predictions to sample...\", percent, \"% (\", item_num, \"/\", pred_len, \")\", end=\"                      \\r\")\n",
    "        pred_ls.append(item[0]['generated_text'])\n",
    "        item_num+=1\n",
    "    pred_ls = np.array(pred_ls)\n",
    "    return pred_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c628e4c-ef01-4059-bfd1-a74c57746c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_kw(model_pipe, val_ds):\n",
    "    \"\"\"This function evaluates the keyword extractor model\n",
    "       by the ROUGE metric.\n",
    "\n",
    "        PARAMETERS\n",
    "        model_pipe - The pipeline object that runs the keyword\n",
    "            extractor model.\n",
    "        val_ds - The dataset to evaluate the keyword extractor model.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"EVALUATING MODEL...\\n\")\n",
    "    ds_len = len(val_ds)\n",
    "    text_labels = val_ds['text'].to_numpy()\n",
    "    prompts = prepare_prompts_for_val(val_ds['question'].to_numpy())\n",
    "    \n",
    "    \n",
    "    loss_f = evaluate.load('rouge')\n",
    "    predictions = []\n",
    "    for out in model_pipe(iterate_prompt(prompts), max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95):\n",
    "        predictions.append(out)\n",
    "    #predictions = generate_text(model_pipe, prompts)\n",
    "    predictions = predictions_to_np(predictions)\n",
    "    \n",
    "    \n",
    "    losses = loss_f.compute(predictions=predictions, references=text_labels)\n",
    "    return losses\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d00bb211-8224-4dc8-83c9-a2f39a856cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATING MODEL...\n",
      "\n",
      "Duration:  1:23:53.766209 sample... 0 % ( 5000 / 5000 )                      \n"
     ]
    }
   ],
   "source": [
    "start = dt.now()\n",
    "results = evaluate_kw(kw_pipe, testing_ds[0:5000])\n",
    "end = dt.now()\n",
    "print(\"Duration: \" , (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa27dc54-b4ee-4371-95bd-86832e75ef5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss metrics:\n",
      "Rouge-1 score: 98.83077071559526%\n",
      "Rouge-2 score: 98.36796605743359%\n",
      "Rouge-L score: 98.81688987203006%\n",
      "Rouge-L Sum score: 98.83023886598299%\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation loss metrics:\")\n",
    "print(\"Rouge-1 score: \" + str(results['rouge1'] * 100) + \"%\")\n",
    "print(\"Rouge-2 score: \" + str(results['rouge2'] * 100) + \"%\")\n",
    "print(\"Rouge-L score: \" + str(results['rougeL'] * 100) + \"%\")\n",
    "print(\"Rouge-L Sum score: \" + str(results['rougeLsum'] * 100) + \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
